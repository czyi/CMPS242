{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyi/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "pixiv/five_0 is completed.\n",
      "4000\n",
      "pixiv/five_1 is completed.\n",
      "8000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "data_x, data_y = [], []\n",
    "num_id = 2\n",
    "img_h=100\n",
    "img_w=100\n",
    "img_c=3\n",
    "img_length = 250*250*3\n",
    "\n",
    "for i in range(num_id):\n",
    "    part_x, part_y = [], []\n",
    "    folder = 'pixiv/five_'+str(i)\n",
    "    for img_file in os.listdir(folder):\n",
    "#         print(folder+'/'+img_file)\n",
    "        img = np.array(Image.open(folder+'/'+img_file))\n",
    "#         img = np.reshape(img, len(img)*len(img[0])*len(img[0][0]))\n",
    "        part_x.append(img/255.0)\n",
    "        \n",
    "        label = [0 for j in range(0, num_id)]\n",
    "        label[i]=1\n",
    "        part_y.append(label)   \n",
    "        if(len(part_x)>=4000):\n",
    "            break\n",
    "    print(len(part_x))\n",
    "    data_x.extend(part_x)\n",
    "    data_y.extend(part_y)\n",
    "    print(folder+' is completed.')\n",
    "\n",
    "print(len(data_x))\n",
    "print(len(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.09411765  0.07058824  0.07058824]\n",
      "   [ 0.13725491  0.11372549  0.11372549]\n",
      "   [ 0.16470589  0.14117648  0.14117648]\n",
      "   ..., \n",
      "   [ 0.43529412  0.35686275  0.32941177]\n",
      "   [ 0.44705883  0.35686275  0.33333334]\n",
      "   [ 0.47450981  0.36470589  0.34901962]]\n",
      "\n",
      "  [[ 0.10980392  0.08627451  0.08627451]\n",
      "   [ 0.14509805  0.12156863  0.12156863]\n",
      "   [ 0.16470589  0.14117648  0.14117648]\n",
      "   ..., \n",
      "   [ 0.44313726  0.36078432  0.34117648]\n",
      "   [ 0.4627451   0.36862746  0.35294119]\n",
      "   [ 0.49411765  0.38431373  0.37254903]]\n",
      "\n",
      "  [[ 0.1254902   0.10196079  0.10196079]\n",
      "   [ 0.14901961  0.1254902   0.1254902 ]\n",
      "   [ 0.16078432  0.13725491  0.13725491]\n",
      "   ..., \n",
      "   [ 0.4509804   0.35686275  0.34117648]\n",
      "   [ 0.47058824  0.37254903  0.35686275]\n",
      "   [ 0.50588238  0.39607844  0.38431373]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.21176471  0.20784314  0.19215687]\n",
      "   [ 0.19607843  0.19215687  0.17254902]\n",
      "   [ 0.19607843  0.19215687  0.17254902]\n",
      "   ..., \n",
      "   [ 0.08627451  0.05882353  0.08627451]\n",
      "   [ 0.08627451  0.05882353  0.08627451]\n",
      "   [ 0.08235294  0.05490196  0.08235294]]\n",
      "\n",
      "  [[ 0.21568628  0.21176471  0.19607843]\n",
      "   [ 0.20392157  0.2         0.18039216]\n",
      "   [ 0.2         0.19607843  0.17647059]\n",
      "   ..., \n",
      "   [ 0.03529412  0.00784314  0.03529412]\n",
      "   [ 0.03529412  0.00784314  0.03529412]\n",
      "   [ 0.03529412  0.00784314  0.03529412]]\n",
      "\n",
      "  [[ 0.21176471  0.20784314  0.19215687]\n",
      "   [ 0.20784314  0.20392157  0.18431373]\n",
      "   [ 0.21176471  0.20784314  0.1882353 ]\n",
      "   ..., \n",
      "   [ 0.02745098  0.          0.02745098]\n",
      "   [ 0.02745098  0.          0.02745098]\n",
      "   [ 0.03137255  0.00392157  0.03137255]]]\n",
      "\n",
      "\n",
      " [[[ 0.56862748  0.58823532  0.74509805]\n",
      "   [ 0.63921571  0.65882355  0.80784315]\n",
      "   [ 0.72549021  0.74901962  0.89019608]\n",
      "   ..., \n",
      "   [ 0.32941177  0.3764706   0.71372551]\n",
      "   [ 0.30588236  0.35294119  0.6901961 ]\n",
      "   [ 0.29803923  0.34509805  0.68235296]]\n",
      "\n",
      "  [[ 0.57647061  0.59607846  0.74509805]\n",
      "   [ 0.63137257  0.65098041  0.80000001]\n",
      "   [ 0.70980394  0.73333335  0.87450981]\n",
      "   ..., \n",
      "   [ 0.30588236  0.35294119  0.68235296]\n",
      "   [ 0.28627452  0.33333334  0.66274512]\n",
      "   [ 0.27450982  0.32156864  0.65098041]]\n",
      "\n",
      "  [[ 0.61960787  0.64313728  0.78431374]\n",
      "   [ 0.65490198  0.67843139  0.81960785]\n",
      "   [ 0.69803923  0.72156864  0.85490197]\n",
      "   ..., \n",
      "   [ 0.33725491  0.40000001  0.70588237]\n",
      "   [ 0.32156864  0.38431373  0.6901961 ]\n",
      "   [ 0.30980393  0.37254903  0.67843139]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.32549021  0.40000001  0.9137255 ]\n",
      "   [ 0.32156864  0.39215687  0.91764706]\n",
      "   [ 0.32156864  0.39215687  0.9254902 ]\n",
      "   ..., \n",
      "   [ 0.74117649  0.49803922  0.33725491]\n",
      "   [ 0.92941177  0.6901961   0.51764709]\n",
      "   [ 0.68235296  0.44313726  0.26666668]]\n",
      "\n",
      "  [[ 0.31764707  0.39215687  0.90588236]\n",
      "   [ 0.3137255   0.38431373  0.90980393]\n",
      "   [ 0.30980393  0.38039216  0.9137255 ]\n",
      "   ..., \n",
      "   [ 0.66274512  0.41960785  0.25882354]\n",
      "   [ 0.89411765  0.65490198  0.48235294]\n",
      "   [ 0.74117649  0.50196081  0.32549021]]\n",
      "\n",
      "  [[ 0.3137255   0.3882353   0.90196079]\n",
      "   [ 0.30980393  0.38039216  0.90588236]\n",
      "   [ 0.30588236  0.3764706   0.90980393]\n",
      "   ..., \n",
      "   [ 0.58823532  0.34509805  0.18431373]\n",
      "   [ 0.85882354  0.61960787  0.44705883]\n",
      "   [ 0.78823531  0.54901963  0.37254903]]]\n",
      "\n",
      "\n",
      " [[[ 0.98039216  0.87450981  0.80784315]\n",
      "   [ 0.98039216  0.87450981  0.80784315]\n",
      "   [ 0.98431373  0.87843138  0.81176472]\n",
      "   ..., \n",
      "   [ 1.          0.87058824  0.83529413]\n",
      "   [ 1.          0.87058824  0.83529413]\n",
      "   [ 1.          0.87058824  0.83529413]]\n",
      "\n",
      "  [[ 0.98039216  0.86666667  0.80392158]\n",
      "   [ 0.97647059  0.87058824  0.80392158]\n",
      "   [ 0.98039216  0.87450981  0.80784315]\n",
      "   ..., \n",
      "   [ 1.          0.87058824  0.83529413]\n",
      "   [ 1.          0.87058824  0.83529413]\n",
      "   [ 1.          0.87058824  0.83529413]]\n",
      "\n",
      "  [[ 0.98431373  0.85882354  0.80784315]\n",
      "   [ 0.98431373  0.85882354  0.80784315]\n",
      "   [ 0.98039216  0.86666667  0.81176472]\n",
      "   ..., \n",
      "   [ 1.          0.87058824  0.83529413]\n",
      "   [ 1.          0.87058824  0.83529413]\n",
      "   [ 1.          0.87058824  0.83529413]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.75294119  0.60784316  0.76862746]\n",
      "   [ 0.75294119  0.60392159  0.75686276]\n",
      "   [ 0.76078433  0.59607846  0.75294119]\n",
      "   ..., \n",
      "   [ 0.99607843  0.86666667  0.83137256]\n",
      "   [ 0.99607843  0.86666667  0.83137256]\n",
      "   [ 0.99607843  0.86666667  0.83137256]]\n",
      "\n",
      "  [[ 0.75294119  0.60784316  0.76862746]\n",
      "   [ 0.75294119  0.60392159  0.75686276]\n",
      "   [ 0.76078433  0.59607846  0.75294119]\n",
      "   ..., \n",
      "   [ 0.99607843  0.86666667  0.83137256]\n",
      "   [ 0.99607843  0.86666667  0.83137256]\n",
      "   [ 0.99607843  0.86666667  0.83137256]]\n",
      "\n",
      "  [[ 0.75294119  0.60784316  0.76862746]\n",
      "   [ 0.75294119  0.60392159  0.75686276]\n",
      "   [ 0.7647059   0.60000002  0.75686276]\n",
      "   ..., \n",
      "   [ 0.99607843  0.86666667  0.83137256]\n",
      "   [ 0.99607843  0.86666667  0.83137256]\n",
      "   [ 0.99607843  0.86666667  0.83137256]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.98823529  0.66666669  0.57254905]\n",
      "   [ 0.97254902  0.65490198  0.58039218]\n",
      "   [ 0.94901961  0.64313728  0.60392159]\n",
      "   ..., \n",
      "   [ 0.84705883  0.50588238  0.46666667]\n",
      "   [ 0.76862746  0.42745098  0.3882353 ]\n",
      "   [ 0.70588237  0.36470589  0.32549021]]\n",
      "\n",
      "  [[ 0.96078432  0.65490198  0.56470591]\n",
      "   [ 0.96078432  0.65882355  0.58823532]\n",
      "   [ 0.96862745  0.67843139  0.63529414]\n",
      "   ..., \n",
      "   [ 0.78823531  0.45882353  0.41568628]\n",
      "   [ 0.74509805  0.41568628  0.37254903]\n",
      "   [ 0.72941178  0.40000001  0.35686275]]\n",
      "\n",
      "  [[ 0.96862745  0.6901961   0.61176473]\n",
      "   [ 0.96470588  0.68235296  0.62352943]\n",
      "   [ 0.94509804  0.67058825  0.63921571]\n",
      "   ..., \n",
      "   [ 0.7764706   0.44705883  0.40784314]\n",
      "   [ 0.74901962  0.41960785  0.38039216]\n",
      "   [ 0.76862746  0.43921569  0.40000001]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.67058825  0.33333334  0.32941177]\n",
      "   [ 0.67058825  0.33725491  0.32549021]\n",
      "   [ 0.67843139  0.33333334  0.32549021]\n",
      "   ..., \n",
      "   [ 0.74901962  0.44705883  0.41568628]\n",
      "   [ 0.74901962  0.44705883  0.41568628]\n",
      "   [ 0.75294119  0.4509804   0.41960785]]\n",
      "\n",
      "  [[ 0.67058825  0.33333334  0.32941177]\n",
      "   [ 0.67058825  0.33725491  0.32549021]\n",
      "   [ 0.67843139  0.33333334  0.32549021]\n",
      "   ..., \n",
      "   [ 0.74901962  0.44705883  0.41568628]\n",
      "   [ 0.74901962  0.44705883  0.41568628]\n",
      "   [ 0.75294119  0.4509804   0.41960785]]\n",
      "\n",
      "  [[ 0.67058825  0.33333334  0.32941177]\n",
      "   [ 0.67058825  0.33725491  0.32549021]\n",
      "   [ 0.67843139  0.33333334  0.32549021]\n",
      "   ..., \n",
      "   [ 0.74901962  0.44705883  0.41568628]\n",
      "   [ 0.74901962  0.44705883  0.41568628]\n",
      "   [ 0.75294119  0.4509804   0.41960785]]]\n",
      "\n",
      "\n",
      " [[[ 0.78039217  0.28235295  0.34901962]\n",
      "   [ 0.78039217  0.28235295  0.34901962]\n",
      "   [ 0.78039217  0.27450982  0.34509805]\n",
      "   ..., \n",
      "   [ 0.60392159  0.67843139  0.70588237]\n",
      "   [ 0.60000002  0.67450982  0.7019608 ]\n",
      "   [ 0.58431375  0.65882355  0.68627453]]\n",
      "\n",
      "  [[ 0.78431374  0.27843139  0.34901962]\n",
      "   [ 0.78431374  0.27843139  0.34901962]\n",
      "   [ 0.78039217  0.27450982  0.34509805]\n",
      "   ..., \n",
      "   [ 0.59215689  0.66666669  0.69411767]\n",
      "   [ 0.60784316  0.68235296  0.70980394]\n",
      "   [ 0.6156863   0.6901961   0.71764708]]\n",
      "\n",
      "  [[ 0.79215688  0.27058825  0.34509805]\n",
      "   [ 0.79215688  0.27058825  0.34509805]\n",
      "   [ 0.78823531  0.26666668  0.34117648]\n",
      "   ..., \n",
      "   [ 0.61176473  0.67843139  0.70588237]\n",
      "   [ 0.60000002  0.66666669  0.69411767]\n",
      "   [ 0.59607846  0.66274512  0.6901961 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.99215686  0.80392158  0.71372551]\n",
      "   [ 0.99215686  0.80392158  0.71372551]\n",
      "   [ 0.99215686  0.80392158  0.71764708]\n",
      "   ..., \n",
      "   [ 0.99215686  0.8392157   0.67843139]\n",
      "   [ 0.99215686  0.8392157   0.67843139]\n",
      "   [ 0.99215686  0.8392157   0.67843139]]\n",
      "\n",
      "  [[ 0.99607843  0.80784315  0.71764708]\n",
      "   [ 0.99607843  0.80784315  0.71764708]\n",
      "   [ 0.99607843  0.80784315  0.72156864]\n",
      "   ..., \n",
      "   [ 0.99607843  0.84313726  0.68235296]\n",
      "   [ 0.99607843  0.84313726  0.68235296]\n",
      "   [ 0.99607843  0.84313726  0.68235296]]\n",
      "\n",
      "  [[ 1.          0.81176472  0.72156864]\n",
      "   [ 1.          0.81176472  0.72156864]\n",
      "   [ 1.          0.81176472  0.72549021]\n",
      "   ..., \n",
      "   [ 0.99607843  0.84313726  0.68235296]\n",
      "   [ 0.99607843  0.84313726  0.68235296]\n",
      "   [ 0.99607843  0.84313726  0.68235296]]]\n",
      "\n",
      "\n",
      " [[[ 0.3764706   0.42352942  0.47058824]\n",
      "   [ 0.3764706   0.41176471  0.47058824]\n",
      "   [ 0.3137255   0.34901962  0.41568628]\n",
      "   ..., \n",
      "   [ 0.24313726  0.27058825  0.29411766]\n",
      "   [ 0.24705882  0.27450982  0.29803923]\n",
      "   [ 0.25490198  0.28235295  0.30588236]]\n",
      "\n",
      "  [[ 0.44313726  0.48235294  0.52156866]\n",
      "   [ 0.43137255  0.47058824  0.51764709]\n",
      "   [ 0.37254903  0.40784314  0.46666667]\n",
      "   ..., \n",
      "   [ 0.25098041  0.27843139  0.30980393]\n",
      "   [ 0.25490198  0.28235295  0.3137255 ]\n",
      "   [ 0.26274511  0.29019609  0.32156864]]\n",
      "\n",
      "  [[ 0.4509804   0.48627451  0.52156866]\n",
      "   [ 0.44313726  0.47450981  0.51764709]\n",
      "   [ 0.41960785  0.44313726  0.49803922]\n",
      "   ..., \n",
      "   [ 0.23921569  0.26666668  0.29803923]\n",
      "   [ 0.24705882  0.27450982  0.30588236]\n",
      "   [ 0.25490198  0.28235295  0.3137255 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.44705883  0.44313726  0.4627451 ]\n",
      "   [ 0.4627451   0.42745098  0.44705883]\n",
      "   [ 0.51764709  0.43529412  0.45490196]\n",
      "   ..., \n",
      "   [ 0.10196079  0.11372549  0.17254902]\n",
      "   [ 0.10980392  0.12156863  0.18039216]\n",
      "   [ 0.12156863  0.13333334  0.19215687]]\n",
      "\n",
      "  [[ 0.40784314  0.40392157  0.42352942]\n",
      "   [ 0.47450981  0.43921569  0.45882353]\n",
      "   [ 0.51372552  0.43137255  0.4509804 ]\n",
      "   ..., \n",
      "   [ 0.10196079  0.11372549  0.17254902]\n",
      "   [ 0.10980392  0.12156863  0.18039216]\n",
      "   [ 0.12156863  0.13333334  0.19215687]]\n",
      "\n",
      "  [[ 0.45882353  0.45490196  0.47450981]\n",
      "   [ 0.48627451  0.4509804   0.47058824]\n",
      "   [ 0.52156866  0.43921569  0.45882353]\n",
      "   ..., \n",
      "   [ 0.12156863  0.13333334  0.19215687]\n",
      "   [ 0.1254902   0.13725491  0.19607843]\n",
      "   [ 0.12941177  0.14117648  0.2       ]]]]\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "data_x = np.array(data_x, dtype='float32')\n",
    "data_y = np.array(data_y, dtype='float32')\n",
    "\n",
    "print(data_x[:10])\n",
    "print(data_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "7200\n",
      "7200\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "order = [i for i in range(len(data_x))]\n",
    "random.shuffle(order)\n",
    "\n",
    "print(len(order))\n",
    "n=int(len(data_x)*9/10)\n",
    "print(n)\n",
    "\n",
    "train_x = [data_x[i] for i in order[0:n]]\n",
    "train_y = [data_y[i] for i in order[0:n]]\n",
    "\n",
    "test_x = [data_x[i] for i in order[n:]]\n",
    "test_y = [data_y[i] for i in order[n:]]\n",
    "\n",
    "print(len(train_x))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400\n",
      "6400\n",
      "6400\n",
      "6400\n",
      "6400\n",
      "6400\n",
      "6400\n",
      "6400\n",
      "6400\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "train_x_list, train_y_list = [], []\n",
    "valid_x_list, valid_y_list = [], []\n",
    "\n",
    "n=int(len(data_x)/10)\n",
    "for i in range(0, 9):\n",
    "#     train_x_list.append([train_x[i] for i in range(0, i*n)+range((i+1)*n), len(train_x)])\n",
    "    cur_x = [train_x[i] for i in range(0, i*n)]\n",
    "    cur_x.extend([train_x[i] for i in range((i+1)*n, len(train_x))])\n",
    "    cur_y = [train_y[i] for i in range(0, i*n)]\n",
    "    cur_y.extend([train_y[i] for i in range((i+1)*n, len(train_x))])\n",
    "    print(len(cur_x))\n",
    "#     print(len(cur_y))\n",
    "    \n",
    "    train_x_list.append(cur_x)\n",
    "    train_y_list.append(cur_y)\n",
    "    \n",
    "    valid_x_list.append([train_x[i] for i in range(i*n, (i+1)*n)])\n",
    "    valid_y_list.append([train_y[i] for i in range(i*n, (i+1)*n)])\n",
    "\n",
    "print(len(train_x_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 25, 25, 32)\n",
      "(?, 7, 7, 64)\n",
      "(?, 2, 2, 128)\n"
     ]
    }
   ],
   "source": [
    "#3-layer\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(), tf.device('/gpu:0'):\n",
    "    labels = tf.placeholder('float', [None, num_id])            #\n",
    "    inputs = tf.placeholder('float', [None, img_h, img_w, img_c])                        #输入的数据占位符\n",
    "#     print(x.shape)\n",
    "#     print(y_actual.shape)\n",
    "\n",
    "    def weight_variable(shape): #定义一个函数，用于初始化所有的权值 W\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(shape): #定义一个函数，用于初始化所有的偏置项 b\n",
    "        initial = tf.constant(0.1, shape=shape)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def conv2d(x, W): #定义一个函数，用于构建卷积层\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    def max_pool(x): #定义一个函数，用于构建池化层\n",
    "        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    #构建网络\n",
    "#     x_image = tf.reshape(inputs, [-1,250,250,3])         #转换输入数据shape,以便于用于网络中\n",
    "    W_conv1 = weight_variable([5, 5, 3, 32])      \n",
    "    b_conv1 = bias_variable([32])       \n",
    "    h_conv1 = tf.nn.relu(conv2d(inputs, W_conv1) + b_conv1)     #第一个卷积层\n",
    "    h_pool1 = max_pool(h_conv1)                                  #第一个池化层\n",
    "    print(h_pool1.shape)#(?, 124, 124, 32)\n",
    "\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)      #第二个卷积层\n",
    "    h_pool2 = max_pool(h_conv2)                                   #第二个池化层\n",
    "    print(h_pool2.shape)#(?, 30, 30, 64)\n",
    "    \n",
    "    W_conv3 = weight_variable([5, 5, 64, 128])\n",
    "    b_conv3 = bias_variable([128])\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)      #第二个卷积层\n",
    "    h_pool3 = max_pool(h_conv3)                                   #第二个池化层\n",
    "    print(h_pool3.shape)#(?, 30, 30, 64)    \n",
    "\n",
    "    # 第三层 是个全连接层,输入维数125*125*64, 输出维数为1024\n",
    "    W_fc1 = weight_variable([2 * 2 * 128, 128])\n",
    "    b_fc1 = bias_variable([128])\n",
    "    h_pool3_flat = tf.reshape(h_pool3, [-1, 2*2*128])              #reshape成向量\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)    #第一个全连接层\n",
    "\n",
    "    keep_prob = tf.placeholder(\"float\") \n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)                  #dropout层\n",
    "\n",
    "    W_fc2 = weight_variable([128, num_id])\n",
    "    b_fc2 = bias_variable([num_id])\n",
    "#     y_predict=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)   #softmax层\n",
    "    y_predict=tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "#     loss = -tf.reduce_sum(labels*tf.log(y_predict))     #交叉熵\n",
    "#     optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)    #梯度下降法\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_predict, labels = labels))\n",
    "    optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(y_predict,1), tf.argmax(labels,1))    \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))    #精确度计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized 0\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[128,101,101,3]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_1_0_1/_1, Variable/read)]]\n\t [[Node: Mean/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_519_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Conv2D', defined at:\n  File \"/home/ziyi/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ziyi/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-dada5681f7db>\", line 27, in <module>\n    h_conv1 = tf.nn.relu(conv2d(inputs, W_conv1) + b_conv1)     #第一个卷积层\n  File \"<ipython-input-12-dada5681f7db>\", line 18, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding='SAME')\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[128,101,101,3]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_1_0_1/_1, Variable/read)]]\n\t [[Node: Mean/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_519_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,101,101,3]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_1_0_1/_1, Variable/read)]]\n\t [[Node: Mean/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_519_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b1c10b51183d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mfeed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeed_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss at step %d: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' accuarcy is '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,101,101,3]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_1_0_1/_1, Variable/read)]]\n\t [[Node: Mean/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_519_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Conv2D', defined at:\n  File \"/home/ziyi/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ziyi/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-dada5681f7db>\", line 27, in <module>\n    h_conv1 = tf.nn.relu(conv2d(inputs, W_conv1) + b_conv1)     #第一个卷积层\n  File \"<ipython-input-12-dada5681f7db>\", line 18, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding='SAME')\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[128,101,101,3]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_1_0_1/_1, Variable/read)]]\n\t [[Node: Mean/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_519_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "batch_start = 0\n",
    "batch_size = 128\n",
    "training_steps = 101\n",
    "\n",
    "for i in range(0, 9):\n",
    "    train_x = train_x_list[i]\n",
    "    train_y = train_y_list[i]\n",
    "#     config = tf.ConfigProto(allow_soft_placement=True)\n",
    "#     config.gpu_options.allocator_type = 'BFC'\n",
    "#     config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "    with tf.Session(graph=graph) as session:\n",
    "    #     saver.restore(session, tf.train.latest_checkpoint('lstm_check'))\n",
    "        tf.global_variables_initializer().run()\n",
    "        print('Initialized', i)\n",
    "        for step in range(training_steps): \n",
    "            if(batch_start+batch_size>len(train_x)):\n",
    "                order = [i for i in range(len(train_x))]\n",
    "                random.shuffle(order)\n",
    "                train_x = [train_x[i] for i in order]\n",
    "                train_y = [train_y[i] for i in order]\n",
    "                batch_start = 0        \n",
    "            feed_x = train_x[batch_start:batch_start+batch_size]\n",
    "            feed_y = train_y[batch_start:batch_start+batch_size]\n",
    "            feed_dict = {inputs: feed_x, labels: feed_y, keep_prob:0.6}\n",
    "            _, l, predictions, accur = session.run([optimizer, loss, labels, accuracy], feed_dict = feed_dict)\n",
    "            if (step % 10 == 0):\n",
    "                print('Loss at step %d: %f' % (step, l), ' accuarcy is ', accur)\n",
    "    #             saver.save(session, 'lstm_check/my-model-1.ckpt', global_step=step+1000)\n",
    "        valid_loss, valid_accur = session.run([loss,accuracy], feed_dict={inputs: valid_x_list[i], labels:  valid_y_list[i], keep_prob:1.0})\n",
    "        print('==valid loss, ', valid_loss, ' valid accur is ', valid_accur)\n",
    "        test_loss, test_accur = session.run([loss,accuracy], feed_dict={inputs: test_x, labels: test_y, keep_prob:1.0})\n",
    "        print('--test loss, ', test_loss, ' test accur is ', test_accur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "9 - 0.35\n",
    "\n",
    "5 - 0.3 - 0.4\n",
    "\n",
    "3 - 0.55+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
